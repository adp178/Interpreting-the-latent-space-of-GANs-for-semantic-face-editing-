{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "data=pd.read_csv(r'C:\\Users\\Prthamesh\\Downloads\\archive (3)\\list_attr_celeba.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list=data.columns.tolist()\n",
    "col_list.remove('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd885258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_data.pkl','rb') as f: \n",
    "    train_files,train_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec610ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2506a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising model for predicting the probabilities of each facial atrribute\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78066e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import misc\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.utils import np_utils\n",
    "import imageio\n",
    "\n",
    "path_d = r'C:\\Users\\Akash\\Downloads\\archive (3)'\n",
    "\n",
    "def prepare_train(file_paths, labels):\n",
    "    images = [imageio.imread(path_d + '\\\\' + path) for path in file_paths]\n",
    "    new_img=[]\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img=cv2.resize(images[i],(128,128))\n",
    "        new_img.append(img)\n",
    "    \n",
    "     \n",
    "    images=np.asarray(new_img)\n",
    "    images=images/255\n",
    "\n",
    "    labels=np.asarray(labels)\n",
    "    labels=np_utils.to_categorical(labels,2)\n",
    "\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dff694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model (each model corresponds to 1 facial attribute)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(40)):\n",
    "    print(i, end = '\\r')\n",
    "    X_train,y_train=prepare_train(train_files[i],train_labels[i])\n",
    "    print(\"Attribute: \",i)\n",
    "    checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "    stop=EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=1, mode='auto')\n",
    "    hist = model.fit(X_train, y_train, batch_size=200, epochs=50,\n",
    "          validation_split=0.2, callbacks=[checkpointer,stop], \n",
    "          verbose=2, shuffle=True) \n",
    "    model.load_weights('model.weights.best.hdf5')\n",
    "    model.save('model'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c97f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "data=pd.read_csv(r'C:\\Users\\Akash\\Downloads\\archive (3)\\list_attr_celeba.csv')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list=data.columns.tolist()\n",
    "col_list.remove('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043790b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os.path as path\n",
    "from scipy import misc\n",
    "\n",
    "IMAGE_PATH = path_d + '\\\\' + 'img_align_celeba/img_align_celeba'\n",
    "file_paths = glob.glob(path.join(IMAGE_PATH, '00*.jpg'))\n",
    "\n",
    "images = [imageio.imread(path) for path in file_paths]\n",
    "images = images[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imageio\n",
    "len(images)\n",
    "#images = [imageio.imread('000026.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6854f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "new_img=[]\n",
    "for i in range(len(images)):\n",
    "    img=cv2.resize(images[i],(128,128))\n",
    "    new_img.append(img)\n",
    "    \n",
    "images=np.asarray(new_img)\n",
    "images=images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9451a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arr = np.zeros((2500,2), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a96013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import os.path as path\n",
    "#\n",
    "s=0\n",
    "t=0\n",
    "acc=[]\n",
    "arr_index = 0\n",
    "\n",
    "for j in [9]:\n",
    "    print(\"\\n\\nAttribute: \",j)\n",
    "    print(col_list[j])\n",
    "    #labels=[]\n",
    "    filename = path.basename(file_paths[i])\n",
    "    index=int(filename.split(\".\")[0])\n",
    "    labels=[]\n",
    "    print(filename,index,end='\\r')\n",
    "    if data[col_list[j]][index-1]==1:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "    labels=np.asarray(labels)\n",
    "    labels=np_utils.to_categorical(labels,2)\n",
    "    model = load_model('model'+str(j)+'.h5')\n",
    "    #print(labels[0])\n",
    "    preds=model.predict(images)\n",
    "    #print(preds)\n",
    "    #preds=np.round(preds, )\n",
    "    #preds[preds>=0.5] = 1\n",
    "    #preds[preds<0.5] = 0\n",
    "    #score=np.sum(preds==labels)/(preds==labels).size\n",
    "    #print(\"Acc:\", score*100) \n",
    "    #acc.append(score*100)\n",
    "    #s=s+np.sum(preds==labels)\n",
    "    #t=t+(preds==labels).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "images = imageio.imread('000026.jpg')\n",
    "img = Image.fromarray(images, 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5159c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e9999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
